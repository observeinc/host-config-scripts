[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  omit_hostname = false
  debug = true
[[outputs.http]]
  namepass = ["tail*"]
  url = "${OBSERVE_HOST}:443/v1/http/telegraf/logs"
  timeout = "5s"
  method = "POST"
  insecure_skip_verify = true
  data_format = "json"
  content_encoding = "gzip"
  [outputs.http.headers]
    Content-Type = "application/json"
    X-Observe-Decoder = "nested"
    Authorization = "Bearer ${OBSERVE_TOKEN}"
[[outputs.http]]
  url = "${OBSERVE_HOST}:443/v1/http/telegraf/metrics"
  # we need to add namepass to both metrics/logs stanzas
  # we will name all metrics `metrics_*` and logs `tail_*` and instruct
  # customers to pass in the appropriate names so they end up hitting the
  # right endpoint
  namedrop = ["tail*"] 
  timeout = "5s"
  method = "POST"
  insecure_skip_verify = true
  data_format = "json"
  content_encoding = "gzip"
  [outputs.http.headers]
    Content-Type = "application/json"
    X-Observe-Decoder = "nested"
    Authorization = "Bearer ${OBSERVE_TOKEN}"
[[inputs.cpu]]
  percpu = true
  totalcpu = false
  collect_cpu_time = false
  report_active = false
[[inputs.disk]]
  ignore_fs = ["tmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs","tracefs"]
[[inputs.net]]
  # no configuration
[[inputs.mem]]
  # no configuration
[[inputs.system]]
  # no configuration
[[inputs.tail]]
  files = ["/var/log/**.log"] # recursively grabs all logs from /var/log
  from_beginning = false
  watch_method = "inotify" # more efficient
  max_undelivered_lines = 1000
  data_format = "value"
  data_type = "string"